{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " business\n",
      "\n",
      " entertainment\n",
      "\n",
      " politics\n",
      "\n",
      " sport\n",
      "\n",
      " tech\n"
     ]
    }
   ],
   "source": [
    "#read the files form the folder\n",
    "main_folder = \"C:/Users/ruman/Downloads/Sci-Kit_Learning/7071/dataset_classification/bbc/\"\n",
    "file_data = pd.DataFrame(columns=['Category','File_Name','Data'])\n",
    "\n",
    "category_list =[]\n",
    "files_list =[]\n",
    "data_list = []\n",
    "\n",
    "for category in os.listdir(main_folder):\n",
    "    print(\"\\n\",category)\n",
    "    subfolder_path = os.path.join(main_folder,category)\n",
    "    for files in os.listdir(subfolder_path):\n",
    "        file_path = os.path.join(subfolder_path,files)\n",
    "        \n",
    "        #print(file_path)\n",
    "        category_list.append(category)\n",
    "        files_list.append(files)\n",
    "        file_ptr = open(file_path)\n",
    "        data = file_ptr.read().split('\\n')\n",
    "        data=list(filter(None, data))\n",
    "        #data = data.split(' ')\n",
    "        data_list.append(data)\n",
    "        \n",
    "file_data['Category'] = category_list\n",
    "file_data['File_Name'] = files_list\n",
    "file_data['Data']  = data_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>[Ad sales boost Time Warner profit, Quarterly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>[Dollar gains on Greenspan speech, The dollar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>[Yukos unit buyer faces loan claim, The owners...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>004.txt</td>\n",
       "      <td>[High fuel prices hit BA's profits, British Ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>005.txt</td>\n",
       "      <td>[Pernod takeover talk lifts Domecq, Shares in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category File_Name                                               Data\n",
       "0  business   001.txt  [Ad sales boost Time Warner profit, Quarterly ...\n",
       "1  business   002.txt  [Dollar gains on Greenspan speech, The dollar ...\n",
       "2  business   003.txt  [Yukos unit buyer faces loan claim, The owners...\n",
       "3  business   004.txt  [High fuel prices hit BA's profits, British Ai...\n",
       "4  business   005.txt  [Pernod takeover talk lifts Domecq, Shares in ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2225</td>\n",
       "      <td>2225</td>\n",
       "      <td>2225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>511</td>\n",
       "      <td>2127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>sport</td>\n",
       "      <td>270.txt</td>\n",
       "      <td>[Millions buy MP3 players in US, One in 10 adu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>511</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category File_Name                                               Data\n",
       "count      2225      2225                                               2225\n",
       "unique        5       511                                               2127\n",
       "top       sport   270.txt  [Millions buy MP3 players in US, One in 10 adu...\n",
       "freq        511         5                                                  2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            511\n",
       "business         510\n",
       "politics         417\n",
       "tech             401\n",
       "entertainment    386\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_data['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ad sales boost Time Warner profit',\n",
       " 'Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.',\n",
       " 'The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.',\n",
       " \"Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.\",\n",
       " 'Time Warner\\'s fourth quarter profits were slightly better than analysts\\' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.',\n",
       " \"TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_data.Data[0][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Data</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>business</td>\n",
       "      <td>343.txt</td>\n",
       "      <td>[Air Jamaica back in state control, The Jamaic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>politics</td>\n",
       "      <td>280.txt</td>\n",
       "      <td>[Blair sees greater Bush consensus, George W B...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>business</td>\n",
       "      <td>385.txt</td>\n",
       "      <td>[Tate &amp; Lyle boss bags top award, Tate &amp; Lyle'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>tech</td>\n",
       "      <td>379.txt</td>\n",
       "      <td>[Apple laptop is 'greatest gadget', The Apple ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>politics</td>\n",
       "      <td>300.txt</td>\n",
       "      <td>[Howard denies split over ID cards, Michael Ho...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category File_Name                                               Data  \\\n",
       "342   business   343.txt  [Air Jamaica back in state control, The Jamaic...   \n",
       "1175  politics   280.txt  [Blair sees greater Bush consensus, George W B...   \n",
       "384   business   385.txt  [Tate & Lyle boss bags top award, Tate & Lyle'...   \n",
       "2202      tech   379.txt  [Apple laptop is 'greatest gadget', The Apple ...   \n",
       "1195  politics   300.txt  [Howard denies split over ID cards, Michael Ho...   \n",
       "\n",
       "      Label  \n",
       "342       0  \n",
       "1175      2  \n",
       "384       0  \n",
       "2202      4  \n",
       "1195      2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 - business, 1 -entertainment, 2 - politics, 3 - sport, 4 - tech\n",
    "label_encode = LabelEncoder()\n",
    "file_data['Label'] = label_encode.fit_transform(file_data['Category'])\n",
    "file_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data into an array\n",
    "data_array = np.array(file_data['Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert into tokens, remove stop words and stem the tokens\n",
    "tokenizer = RegexpTokenizer('[A-Za-z]\\w+')\n",
    "for idx in range(len(data_array)):   \n",
    "    data_array[idx] = tokenizer.tokenize(str(data_array[idx]))\n",
    "    \n",
    "data_array = [[ps.stem(token) for token in doc if token not in stop_words] for doc in data_array]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Data</th>\n",
       "      <th>Label</th>\n",
       "      <th>Token_Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>051.txt</td>\n",
       "      <td>[Foxx and Swank win US awards, Jamie Foxx and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[foxx, swank, win, US, award, jami, foxx, hila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>156.txt</td>\n",
       "      <td>[Usher leads Soul Train shortlist, Chart-toppi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[usher, lead, soul, train, shortlist, chart, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>tech</td>\n",
       "      <td>262.txt</td>\n",
       "      <td>[Broadband steams ahead in the US, More and mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>[broadband, steam, ahead, US, more, american, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>business</td>\n",
       "      <td>432.txt</td>\n",
       "      <td>[BA to suspend two Saudi services, British Air...</td>\n",
       "      <td>0</td>\n",
       "      <td>[BA, suspend, two, saudi, servic, british, air...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>politics</td>\n",
       "      <td>077.txt</td>\n",
       "      <td>[Brown names 16 March for Budget, Chancellor G...</td>\n",
       "      <td>2</td>\n",
       "      <td>[brown, name, march, budget, chancellor, gordo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>sport</td>\n",
       "      <td>096.txt</td>\n",
       "      <td>[Van Nistelrooy set to return, Manchester Unit...</td>\n",
       "      <td>3</td>\n",
       "      <td>[van, nistelrooy, set, return, manchest, unit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>265.txt</td>\n",
       "      <td>[Abba reunite for musical premiere, The origin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[abba, reunit, music, premier, the, origin, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>191.txt</td>\n",
       "      <td>[Little Britain vies for TV trophy, BBC hits L...</td>\n",
       "      <td>1</td>\n",
       "      <td>[littl, britain, vie, TV, trophi, bbc, hit, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>politics</td>\n",
       "      <td>303.txt</td>\n",
       "      <td>[Election deal faltered over Heath role, The T...</td>\n",
       "      <td>2</td>\n",
       "      <td>[elect, deal, falter, heath, role, the, tori, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>politics</td>\n",
       "      <td>140.txt</td>\n",
       "      <td>[UK helps raped Rwandan women, Britain is to g...</td>\n",
       "      <td>2</td>\n",
       "      <td>[UK, help, rape, rwandan, women, britain, give...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Category File_Name  \\\n",
       "560   entertainment   051.txt   \n",
       "665   entertainment   156.txt   \n",
       "2085           tech   262.txt   \n",
       "431        business   432.txt   \n",
       "972        politics   077.txt   \n",
       "1408          sport   096.txt   \n",
       "774   entertainment   265.txt   \n",
       "700   entertainment   191.txt   \n",
       "1198       politics   303.txt   \n",
       "1035       politics   140.txt   \n",
       "\n",
       "                                                   Data  Label  \\\n",
       "560   [Foxx and Swank win US awards, Jamie Foxx and ...      1   \n",
       "665   [Usher leads Soul Train shortlist, Chart-toppi...      1   \n",
       "2085  [Broadband steams ahead in the US, More and mo...      4   \n",
       "431   [BA to suspend two Saudi services, British Air...      0   \n",
       "972   [Brown names 16 March for Budget, Chancellor G...      2   \n",
       "1408  [Van Nistelrooy set to return, Manchester Unit...      3   \n",
       "774   [Abba reunite for musical premiere, The origin...      1   \n",
       "700   [Little Britain vies for TV trophy, BBC hits L...      1   \n",
       "1198  [Election deal faltered over Heath role, The T...      2   \n",
       "1035  [UK helps raped Rwandan women, Britain is to g...      2   \n",
       "\n",
       "                                             Token_Data  \n",
       "560   [foxx, swank, win, US, award, jami, foxx, hila...  \n",
       "665   [usher, lead, soul, train, shortlist, chart, t...  \n",
       "2085  [broadband, steam, ahead, US, more, american, ...  \n",
       "431   [BA, suspend, two, saudi, servic, british, air...  \n",
       "972   [brown, name, march, budget, chancellor, gordo...  \n",
       "1408  [van, nistelrooy, set, return, manchest, unit,...  \n",
       "774   [abba, reunit, music, premier, the, origin, st...  \n",
       "700   [littl, britain, vie, TV, trophi, bbc, hit, li...  \n",
       "1198  [elect, deal, falter, heath, role, the, tori, ...  \n",
       "1035  [UK, help, rape, rwandan, women, britain, give...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_data['Token_Data']=data_array\n",
    "file_data.sample(10)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Data</th>\n",
       "      <th>Label</th>\n",
       "      <th>Token_Data</th>\n",
       "      <th>Token_Data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>[Ad sales boost Time Warner profit, Quarterly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Ad, sale, boost, time, warner, profit, quarte...</td>\n",
       "      <td>Ad sale boost time warner profit quarterli pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>[Dollar gains on Greenspan speech, The dollar ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[dollar, gain, greenspan, speech, the, dollar,...</td>\n",
       "      <td>dollar gain greenspan speech the dollar hit hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category File_Name                                               Data  \\\n",
       "0  business   001.txt  [Ad sales boost Time Warner profit, Quarterly ...   \n",
       "1  business   002.txt  [Dollar gains on Greenspan speech, The dollar ...   \n",
       "\n",
       "   Label                                         Token_Data  \\\n",
       "0      0  [Ad, sale, boost, time, warner, profit, quarte...   \n",
       "1      0  [dollar, gain, greenspan, speech, the, dollar,...   \n",
       "\n",
       "                                         Token_Data2  \n",
       "0  Ad sale boost time warner profit quarterli pro...  \n",
       "1  dollar gain greenspan speech the dollar hit hi...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace , with space in token list\n",
    "file_data['Token_Data2'] = [ ' '.join(map(str,tok)) for tok in file_data['Token_Data']]\n",
    "\n",
    "file_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split data into test and training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(file_data['Token_Data2'].values,file_data['Label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1668,), (557,), (1668,), (557,))"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can smith work scottish wonder the worst kept secret scottish footbal reveal thursday walter smith name new nation manag from moment berti vogt miser tenur charg scotland end former ranger everton boss overwhelm favourit post but smith man must one hardest job footbal the year old take time nation side doldrum scotland reach major final sinc world cup reach germani look near imposs pick two point open three game qualifi race and fifa rank see scotland list time low th like estonia ghana angola thailand scotland bless qualiti player experi top level smith get best meagr resourc smith track record make impress read wide respect within game the man alex ferguson assist scotland play world cup seven leagu titl ranger and appoint wide endors mani game top name includ ferguson graem souness took ibrox assist charact like souness ferguson current ibrox manag alex mcleish cite smith experi expans knowledg scottish game much made vogt inabl express player media that certainli case smith the former dunde unit dumbarton full back manageri old school straight talk never slow let player know expect better often use colour invect but rememb vogt came scotland impress curriculum vita world cup winner player european championship winner manag smith inherit problem vogt callow squad player except talent and remain seen smith experi rash call off blight much vogt prepar work fresh start scottish nation team imper smith wide regard safe pair hand but safe pair hand enough adroit hand magician might requir'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(557,)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form tf-idf vector\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = [\"This is sports column\"]\n",
    "test_input = np.array(test_input)\n",
    "x_train_vector = vectorizer.fit_transform(x_train)\n",
    "x_test_vector =vectorizer.transform(x_test)\n",
    "test_vector = vectorizer.transform(test_input)\n",
    "pickle.dump(x_train, open(\"Training_data.npy\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1668, 16925), (557, 16925), (1, 16925))"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_vector.shape, x_test_vector.shape,test_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business', 'entertainment', 'politics', 'sport', 'tech']\n"
     ]
    }
   ],
   "source": [
    "print(list(label_encode.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use multiple classifiers and grid search for prediction\n",
    "def ML_modeling(models, params, X_train, X_test, y_train, y_test):    \n",
    "    \n",
    "    if not set(models.keys()).issubset(set(params.keys())):\n",
    "        raise ValueError('Some estimators are missing parameters')\n",
    "\n",
    "    for key in models.keys():\n",
    "    \n",
    "        model = models[key]\n",
    "        param = params[key]\n",
    "        gs = GridSearchCV(model, param, cv=10, error_score=0, refit=True)\n",
    "        gs.fit(X_train, y_train)\n",
    "        y_pred = gs.predict(X_test)\n",
    "        \n",
    "        # Print scores for the classifier\n",
    "        print(key, ':', gs.best_params_)\n",
    "        print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (accuracy_score(y_test, y_pred), precision_score(y_test, y_pred, average='macro'), recall_score(y_test, y_pred, average='macro'), f1_score(y_test, y_pred, average='macro')))\n",
    "    \n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference : https://www.kaggle.com/rockystats/bbc-text-classification-word2vec-vs-tf-idf\n",
    "# Preparing to make a pipeline \n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(), \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params\n",
    "params = {\n",
    "    'Naive Bayes': { 'alpha': [0.5, 1], 'fit_prior': [True, False] }, \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes : {'alpha': 0.5, 'fit_prior': True}\n",
      "Accuracy: 0.989 \tPrecision: 0.989 \tRecall: 0.989 \t\tF1: 0.989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model_NB = ML_modeling(models, params, x_train_vector, x_test_vector, y_train, y_test)\n",
    "## ML_modeling method also prints performance scores for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of GridSearchCV(cv=10, error_score=0, estimator=MultinomialNB(),\n",
       "             param_grid={'alpha': [0.5, 1], 'fit_prior': [True, False]})>"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model_NB.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the subject classification model:\n",
    "def vectorize(test_input):\n",
    "    #stem and  stop words\n",
    "    global vectorizer\n",
    "    stop_words = stopwords.words('english')\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    #convert into tokens, remove stop words and stem the tokens\n",
    "    tokenizer = RegexpTokenizer('[A-Za-z]\\w+')\n",
    "    test_input = tokenizer.tokenize(str(test_input))\n",
    "    \n",
    "    test_input = [ps.stem(token) for token in test_input if token not in stop_words]      \n",
    "#     print(test_input)\n",
    "\n",
    "    test_input =  [' '.join(map(str,test_input))]\n",
    "    print(test_input)\n",
    "    test_input = np.array(test_input)\n",
    "#     print(test_input)\n",
    "    test_vector = vectorizer.transform(test_input)\n",
    "#     print(test_vector)    \n",
    "    \n",
    "    return test_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "hello World sensex\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_input = \"hello World sensex\"\n",
    "# test_input= test_input.replace('\"', ' ')\n",
    "print(type(test_input))\n",
    "print(test_input)\n",
    "\n",
    "# test_input = np.array(test_input)\n",
    "# print(test_input)\n",
    "# test_vector = vectorizer.transform(test_input)\n",
    "# print(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello world sensex']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([3]),\n",
       " array([[0.23188525, 0.16243363, 0.16392107, 0.26346985, 0.17829021]]),\n",
       " 0.2634698489399912)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict the subject classifiction\n",
    "test_vector= vectorize(test_input)\n",
    "y_pred = trained_model_NB.predict(test_vector)\n",
    "y_prob = trained_model_NB.predict_proba(test_vector)\n",
    "y_pred,y_prob,y_prob[0][np.argmax(y_prob)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sport']\n"
     ]
    }
   ],
   "source": [
    "# save the model to disk\n",
    "filename = 'subject_Classification_NB.sav'\n",
    "pickle.dump(trained_model_NB, open(filename, 'wb'))\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.predict(test_vector)\n",
    "print(label_encode.inverse_transform(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
